{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joms-hub/SEE/blob/main/output/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Sessa Empirical Estimator (SEE)\n",
        "\n",
        "*Assignment by Jomar Cunado and January Venice Toledo*\n",
        "\n",
        "---\n",
        "## Background and Purpose  \n",
        "The **Sessa Empirical Estimator (SEE)** is a data-driven method designed to estimate the duration of prescription drug use, particularly when information on dosage and daily consumption is incomplete or unavailable. It offers a more **systematic and objective** approach compared to traditional methods, which often rely on assumptions.\n",
        "\n",
        "In pharmacoepidemiology—the study of medication use and its effects on populations—it is crucial to determine how long patients remain on a given treatment. Understanding this duration helps researchers assess **treatment adherence, effectiveness, and potential risks**. However, prescription records often lack details on intended treatment duration, making it difficult to track continuous drug exposure accurately.\n",
        "\n",
        "To address this, SEE was developed as a **more precise alternative** to traditional approaches like **Researcher-Defined Duration (RDD)**, which assumes a fixed daily dosage. Instead, SEE uses **real-world prescription patterns** to estimate treatment duration, minimizing bias and improving accuracy.\n",
        "\n",
        "## How It Works  \n",
        "SEE operates in several key steps:\n",
        "\n",
        "1. **Analyzing prescription refill patterns**  \n",
        "   - The method examines how often patients refill their prescriptions. To avoid distortions caused by irregular refill behaviors, SEE filters out unusually long gaps between refills.\n",
        "\n",
        "2. **Selecting representative prescription pairs**  \n",
        "   - Instead of analyzing every refill, SEE selects one random pair per patient to **avoid overrepresentation** of frequent refills.\n",
        "\n",
        "3. **Grouping similar refill behaviors**  \n",
        "   - Using a **k-means clustering algorithm**, SEE identifies different prescription duration patterns across the patient population. This ensures that prescription lengths are estimated based on **realistic usage trends** rather than arbitrary assumptions.\n",
        "\n",
        "4. **Determining treatment exposure periods**  \n",
        "   - For each cluster, SEE calculates a **median prescription duration** and applies it to estimate how long a patient was likely exposed to the medication.\n",
        "\n",
        "## Effectiveness and Accuracy  \n",
        "SEE has been tested in both **simulated data** and **real-world prescription records**:\n",
        "\n",
        "- In controlled simulations, it achieved **96% accuracy** in estimating prescription durations.\n",
        "- In studies using Danish healthcare data, SEE demonstrated **high sensitivity (78–95%)**, outperforming traditional methods.\n",
        "- When compared to RDD, SEE showed **lower error rates and greater adaptability** across different drug types.\n",
        "\n",
        "## Applications in Research  \n",
        "SEE has been applied in several studies to improve our understanding of **medication adherence and co-exposure** to multiple drugs. Examples include:\n",
        "\n",
        "- **Antihypertensive medications**: SEE was used to track how long patients remained on combination therapies.\n",
        "- **Drug safety studies**: It helped assess whether prolonged exposure to the anti-seizure drug **lamotrigine** was linked to an increased risk of cardiovascular events.\n",
        "- **Pharmacoepidemiological research**: SEE has been integrated into frameworks to enhance the accuracy of drug exposure assessments.\n",
        "\n",
        "## Significance\n",
        "By relying on **data-driven insights rather than fixed assumptions**, SEE provides a **more reliable and flexible** way to estimate prescription durations. This improves the quality of research in drug safety, treatment effectiveness, and public health policy, ultimately helping to ensure that medications are used safely and effectively in real-world settings.\n"
      ],
      "metadata": {
        "id": "6cgSDUbW4R55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A. INITIALIZATION\n",
        "\n",
        "## I. Import Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "IyzUiYTwgVT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import gaussian_kde\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# DBScan Libraries\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if file exists before attempting to load dataset\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "3Ah_bovdgot_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Setup Sample Data\n"
      ],
      "metadata": {
        "id": "RxtzC9CLgqtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './csv/med_events.csv'\n",
        "\n",
        "if Path(file_path).is_file():\n",
        "    medical_events = pnd.read_csv(file_path)\n",
        "    print(\"CSV file loaded successfully!\")\n",
        "\n",
        "    # Convert date column to datetime (assuming 'DATE' is the column name in your CSV)\n",
        "    medical_events[\"DATE\"] = pnd.to_datetime(medical_events[\"DATE\"])\n",
        "\n",
        "    # Change column names\n",
        "    medical_events.columns = [\"pnr\", \"eksd\", \"perday\", \"ATC\", \"dur_original\"]\n",
        "\n",
        "    # Display the first few rows\n",
        "    print(medical_events.head())\n",
        "else:\n",
        "    print(f\"Error: File not found at {file_path}. Ensure the file exists.\")"
      ],
      "metadata": {
        "id": "N9f0w7PpjJjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B. Callable Functions\n",
        "\n",
        "## I. SEE using **K-means**"
      ],
      "metadata": {
        "id": "7-8_wtg6kZZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def see_k(arg1):\n",
        "    # Filter dataset for the specified medication\n",
        "    filtered_data = medical_events[medical_events[\"ATC\"] == arg1].copy()\n",
        "\n",
        "    # Sort and create a prior prescription date column\n",
        "    filtered_data = filtered_data.sort_values([\"pnr\", \"eksd\"]).copy()\n",
        "    filtered_data[\"prev_eksd\"] = filtered_data.groupby(\"pnr\")[\"eksd\"].shift(1)\n",
        "\n",
        "    # Remove rows where prev_eksd is NaN\n",
        "    filtered_data = filtered_data.dropna().copy()\n",
        "\n",
        "    # Select one random record per patient\n",
        "    filtered_data = filtered_data.groupby(\"pnr\").sample(n=1, random_state=5678).copy()\n",
        "\n",
        "    # Compute event interval (time difference)\n",
        "    filtered_data[\"event_interval\"] = (filtered_data[\"eksd\"] - filtered_data[\"prev_eksd\"]).dt.days\n",
        "\n",
        "    # Remove non-positive event intervals\n",
        "    filtered_data = filtered_data[filtered_data[\"event_interval\"] > 0].copy()\n",
        "\n",
        "    # Compute ECDF\n",
        "    if filtered_data.empty:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if no valid data\n",
        "\n",
        "    sorted_intervals = nmp.sort(filtered_data[\"event_interval\"])\n",
        "    ecdf_y = nmp.arange(1, len(sorted_intervals) + 1) / len(sorted_intervals)\n",
        "\n",
        "    # Keep only the lower 80% of ECDF\n",
        "    max_value = sorted_intervals[int(0.8 * len(sorted_intervals))]\n",
        "    filtered_subset = filtered_data[filtered_data[\"event_interval\"] <= max_value].copy()\n",
        "\n",
        "    # Ensure filtered_subset is not empty\n",
        "    if filtered_subset.empty:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if no valid data\n",
        "\n",
        "    # Remove non-positive values before applying log\n",
        "    filtered_subset = filtered_subset[filtered_subset[\"event_interval\"] > 0]\n",
        "\n",
        "    # Density plot of log-transformed event intervals\n",
        "    if len(filtered_subset) > 1:  # Ensure there's enough data for KDE\n",
        "        kde = gaussian_kde(nmp.log(filtered_subset[\"event_interval\"]))\n",
        "        x_values = nmp.linspace(min(nmp.log(filtered_subset[\"event_interval\"])),\n",
        "                                max(nmp.log(filtered_subset[\"event_interval\"])), 100)\n",
        "        y_values = kde(x_values)\n",
        "    else:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if insufficient data for KDE\n",
        "\n",
        "    # Silhouette Analysis\n",
        "    scaler = StandardScaler()\n",
        "    scaled_intervals = scaler.fit_transform(x_values.reshape(-1, 1))\n",
        "\n",
        "    best_clusters = []\n",
        "    best_score = -1\n",
        "    optimal_k = 2\n",
        "\n",
        "    for k in range(2, 10):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=5678, n_init=10)\n",
        "        labels = kmeans.fit_predict(scaled_intervals)\n",
        "        score = silhouette_score(scaled_intervals, labels)\n",
        "        best_clusters.append((k, score))\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            optimal_k = k\n",
        "\n",
        "    # K-means Clustering\n",
        "    filtered_subset = filtered_subset.copy()  # Ensure a fresh copy before modification\n",
        "    filtered_subset.loc[:, \"cluster\"] = KMeans(n_clusters=optimal_k, random_state=5678, n_init=10).fit_predict(filtered_subset[[\"event_interval\"]])\n",
        "\n",
        "    # Cluster summary\n",
        "    cluster_summary = filtered_subset.groupby(\"cluster\")[\"event_interval\"].agg([\"min\", \"max\", \"median\"]).reset_index()\n",
        "\n",
        "    # Merge clusters back to main dataset\n",
        "    results = filtered_subset.merge(cluster_summary, on=\"cluster\", how=\"left\")\n",
        "    results = results[(results[\"event_interval\"] >= results[\"min\"]) & (results[\"event_interval\"] <= results[\"max\"])]\n",
        "\n",
        "    # Assign cluster to all data\n",
        "    final_result = medical_events[medical_events[\"ATC\"] == arg1].copy()\n",
        "    final_result = final_result.merge(results[[\"pnr\", \"median\", \"cluster\"]], on=\"pnr\", how=\"left\")\n",
        "\n",
        "    # Fill missing cluster values safely\n",
        "    final_result[\"cluster\"] = final_result[\"cluster\"].fillna(0)\n",
        "    final_result[\"median\"] = final_result[\"median\"].fillna(results[\"median\"].median())\n",
        "\n",
        "    return final_result"
      ],
      "metadata": {
        "id": "uKIk7G57kkMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. SEE using **DBScan**"
      ],
      "metadata": {
        "id": "06UJps4Rl42-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def see_dbscan(arg1):\n",
        "    # Filter dataset for the specified medication\n",
        "    filtered_data = medical_events[medical_events[\"ATC\"] == arg1].copy()\n",
        "\n",
        "    # Sort and create a prior prescription date column\n",
        "    filtered_data = filtered_data.sort_values([\"pnr\", \"eksd\"]).copy()\n",
        "    filtered_data[\"prev_eksd\"] = filtered_data.groupby(\"pnr\")[\"eksd\"].shift(1)\n",
        "\n",
        "    # Remove rows where prev_eksd is NaN\n",
        "    filtered_data = filtered_data.dropna().copy()\n",
        "\n",
        "    # Select one random record per patient\n",
        "    filtered_data = filtered_data.groupby(\"pnr\").sample(n=1, random_state=5678).copy()\n",
        "\n",
        "    # Compute event interval (time difference)\n",
        "    filtered_data[\"event_interval\"] = (filtered_data[\"eksd\"] - filtered_data[\"prev_eksd\"]).dt.days\n",
        "\n",
        "    # Remove non-positive event intervals\n",
        "    filtered_data = filtered_data[filtered_data[\"event_interval\"] > 0].copy()\n",
        "\n",
        "    # Compute ECDF\n",
        "    if filtered_data.empty:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if no valid data\n",
        "\n",
        "    sorted_intervals = nmp.sort(filtered_data[\"event_interval\"])\n",
        "    ecdf_y = nmp.arange(1, len(sorted_intervals) + 1) / len(sorted_intervals)\n",
        "\n",
        "    # Keep only the lower 80% of ECDF\n",
        "    max_value = sorted_intervals[int(0.8 * len(sorted_intervals))]\n",
        "    filtered_subset = filtered_data[filtered_data[\"event_interval\"] <= max_value].copy()\n",
        "\n",
        "    # Ensure filtered_subset is not empty\n",
        "    if filtered_subset.empty:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if no valid data\n",
        "\n",
        "    # Remove non-positive values before applying log\n",
        "    filtered_subset = filtered_subset[filtered_subset[\"event_interval\"] > 0]\n",
        "\n",
        "    # Density plot of log-transformed event intervals\n",
        "    if len(filtered_subset) > 1:  # Ensure there's enough data for KDE\n",
        "        kde = gaussian_kde(nmp.log(filtered_subset[\"event_interval\"]))\n",
        "        x_values = nmp.linspace(min(nmp.log(filtered_subset[\"event_interval\"])),\n",
        "                                max(nmp.log(filtered_subset[\"event_interval\"])), 100)\n",
        "        y_values = kde(x_values)\n",
        "    else:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if insufficient data for KDE\n",
        "\n",
        "    # Normalize the data for clustering\n",
        "    scaler = StandardScaler()\n",
        "    scaled_intervals = scaler.fit_transform(filtered_subset[[\"event_interval\"]])\n",
        "\n",
        "    # Determine the optimal epsilon (eps) using k-distance method\n",
        "    if len(scaled_intervals) < 5:\n",
        "        return pnd.DataFrame()  # Return empty DataFrame if not enough data for DBSCAN\n",
        "\n",
        "    neighbor = NearestNeighbors(n_neighbors=5)\n",
        "    neighbor.fit(scaled_intervals)\n",
        "    distances, _ = neighbor.kneighbors(scaled_intervals)\n",
        "    k_distances = nmp.sort(distances[:, -1])  # Take the 5th neighbor distance\n",
        "\n",
        "    # Choose eps as the \"knee\" point (approximation: 90th percentile of distances)\n",
        "    eps_value = nmp.percentile(k_distances, 90)\n",
        "\n",
        "    # Apply DBSCAN clustering\n",
        "    dbscan = DBSCAN(eps=eps_value, min_samples=5)\n",
        "    filtered_subset.loc[:, \"cluster\"] = dbscan.fit_predict(scaled_intervals)\n",
        "\n",
        "    # Handle noise points (DBSCAN assigns -1 to noise)\n",
        "    filtered_subset.loc[filtered_subset[\"cluster\"] == -1, \"cluster\"] = nmp.nan\n",
        "\n",
        "    # Cluster summary\n",
        "    cluster_summary = filtered_subset.groupby(\"cluster\")[\"event_interval\"].agg([\"min\", \"max\", \"median\"]).reset_index()\n",
        "\n",
        "    # Merge clusters back to main dataset\n",
        "    results = filtered_subset.merge(cluster_summary, on=\"cluster\", how=\"left\")\n",
        "    results = results[(results[\"event_interval\"] >= results[\"min\"]) & (results[\"event_interval\"] <= results[\"max\"])]\n",
        "\n",
        "    # Assign cluster to all data\n",
        "    final_result = medical_events[medical_events[\"ATC\"] == arg1].copy()\n",
        "    final_result = final_result.merge(results[[\"pnr\", \"median\", \"cluster\"]], on=\"pnr\", how=\"left\")\n",
        "\n",
        "    # Fill missing cluster values safely\n",
        "    final_result[\"cluster\"] = final_result[\"cluster\"].fillna(0)\n",
        "    final_result[\"median\"] = final_result[\"median\"].fillna(results[\"median\"].median())\n",
        "\n",
        "    return final_result"
      ],
      "metadata": {
        "id": "SWf_CObCl8N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C. Execution\n",
        "\n",
        "## I. Using **K-means**\n"
      ],
      "metadata": {
        "id": "RdWqKyW2pRlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "med_a = see(\"medA\")\n",
        "med_a"
      ],
      "metadata": {
        "id": "bZNw1MEnpqet"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}